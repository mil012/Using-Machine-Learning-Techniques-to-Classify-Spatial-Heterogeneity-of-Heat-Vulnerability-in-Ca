library(dplyr)
library(rpart)
library(randomForest)
library(lubridate)
install.packages("corrplot")
library(corrplot)

final_test <- read.csv("final_test.csv")
final_train <- read.csv("final_train.csv")

trained <- final_train[sample(nrow(final_train), 100000), ]
trained <- subset(trained, select = -c(treecanopy_pctile, automobile_pctile))
final_test <- subset(final_test, select = -c(treecanopy_pctile, automobile_pctile))
final_test <- na.omit(final_test)
trained <- na.omit(trained)

trained$heat_illness <- as.factor(trained$heat_illness)
trained$month <- as.factor(trained$month)
trained$year <- as.factor(trained$year)
trained$cluster <- as.factor(trained$cluster)

final_test$heat_illness <- as.factor(final_test$heat_illness)
final_test$month <- as.factor(final_test$month)
final_test$year <- as.factor(final_test$year)
final_test$cluster <- as.factor(final_test$cluster)

final_test <- subset(final_test, select=-X)
trained <- subset(trained, select=-X)

#Make prediction and compare to actual outcome
accuracy_results <- function(tree, test){
  predictions <- predict(tree, test, type = 'class')
  table_mat <- table(test$heat_illness, predictions)
  print(table_mat)
  accuracy_Test <- sum(diag(table_mat))/sum(table_mat)
  print(paste("Accuracy for test", accuracy_Test))
}

#Perform random forest
rf <- randomForest(heat_illness~., ntree = 100, mtry = 2, data = trained, importance = TRUE)
rf
accuracy_results(rf, final_test)
plot(rf)
rf$importance
varImpPlot(rf)

#Build decision tree
ca_tree <- rpart(heat_illness~., data = trained, method = 'class')
ca_tree

#Test tree
accuracy_results(ca_tree, final_test)
